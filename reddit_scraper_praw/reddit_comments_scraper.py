# -*- coding: utf-8 -*-
"""reddit_comments_scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vHpY69lBHXGLab40snLnD5LG9nxZ4obz
"""

import pandas as pd
from prawcore.exceptions import Forbidden

# Import Libraries
import praw
from praw.models import MoreComments

def scrape_comments(url):
  # Please change with your own client id, client secret, and user agent
  # Initializing the client id, client secret, and user agent
  reddit_read_only = praw.Reddit(client_id= '', #Enter your client id
                     client_secret= '', #Enter your secret key
                     user_agent= '', #Enter your user agent
                     check_for_async = False)

  # Creating a submission object
  submission = reddit_read_only.submission(url=url)
  return submission

posts_dict = {"Title": [], "Post Text": [],
              "ID": [], "Score": [],
              "Total Comments": [], "Post URL": []
              }

post_comments = scrape_comments(url)  #Please use the url of the reddit post
#Print post id
print(post_comments)

all_comments = []
for comment in post_comments.comments:
    if type(comment) == MoreComments:
        continue

    all_comments.append(comment.body)

# creating a dataframe
comments_df = pd.DataFrame(all_comments, columns=['comment'])
# saving the comments
comments_df.to_excel("file_op_path/output.xlsx", index=True)  #Enter the file output path